# Прогнозирование конечных свойств новых композиционных материалов

**Выпускная квалификационная работа**  
Курс: **Data Science Pro**  
Студентка: **Бинеева Амина Олеговна**  
МГТУ им. Н.Э. Баумана, Центр НТИ «Цифровое материаловедение: новые материалы и вещества»  
2025 г.

---

## Описание проекта

Проект направлен на решение двух взаимосвязанных задач в области цифрового материаловедения:

1. **Прямая задача**: прогнозирование механических свойств композиционного материала —  
   - Модуль упругости при растяжении (ГПа)  
   - Прочность при растяжении (МПа)  
   по 11 входным параметрам (состав, плотность, режимы отверждения и др.).

2. **Обратная задача**: рекомендация оптимального **соотношения матрица–наполнитель** по заданным целевым значениям модуля упругости и прочности.

Решение основано на реальных производственных данных, предоставленных Центром НТИ при МГТУ им. Н.Э. Баумана.

---

## Используемые методы

- **Прямая задача**: обучены и сравнены три модели:
  - Random Forest  
  - Support Vector Regression (SVR)  
  - XGBoost (**выбрана как лучшая**)
- **Обратная задача**: полносвязная нейронная сеть (3 скрытых слоя + Dropout)
- **Предобработка**: удаление выбросов (метод IQR), стандартизация (`StandardScaler`)
- **Оценка качества**: MAE, RMSE, R²

---

## Консольное приложение

Приложение позволяет:
- **Режим 1**: прогнозировать свойства по составу  
- **Режим 2**: рекомендовать соотношение по желаемым свойствам

### Требования
- Python 3.8+
- Библиотеки: `pandas`, `numpy`, `scikit-learn`, `xgboost`, `tensorflow`, `matplotlib`, `seaborn`

Установка зависимостей:
```bash
pip install -r requirements.txt

## Структура репозитория
```
.
├── models/
│ ├── best_model_forward.pkl # Лучшая модель прямой задачи (XGBoost)
│ ├── input_features.pkl # Список входных признаков для валидации
│ ├── nn_inverse_model.keras # Нейронная сеть для обратной задачи
│ ├── scaler_X.pkl # Стандартизатор входных признаков (прямая задача)
│ ├── scaler_X_inv.pkl # Стандартизатор входов (обратная задача)
│ ├── scaler_y.pkl # Стандартизатор целевых переменных (прямая задача)
│ └── scaler_y_inv.pkl # Стандартизатор выхода (обратная задача)
├── results/
│ ├── eda_boxplots.png # Диаграммы размаха (выбросы)
│ ├── eda_correlation.png # Матрица корреляций
│ ├── eda_histograms.png # Распределения признаков
│ ├── eda_pairplot.png # Попарные зависимости
│ ├── nn_loss.png # Кривые потерь при обучении нейросети
│ ├── norm_Количество_отвердителя,_м.%.png
│ ├── norm_Плотность,_кг_м3.png
│ ├── norm_Поверхностная_плотность,_г_м2.png
│ ├── norm_Потребление_смолы,_г_м2.png
│ ├── norm_Содержание_эпоксидных_групп,%_2.png
│ ├── norm_Соотношение_матрица-наполнитель.png
│ ├── norm_Температура_вспышки,_С_2.png
│ └── norm_модуль_упругости,_ГПа.png
├── Бинеева_ВКР по курсу Data Science PRO.ipynb # Основной ноутбук с кодом
├── main_app.py # Консольное приложение
├── train_and_save_models.py # Скрипт обучения и сохранения моделей
├── requirements.txt # Зависимости Python
└── README.md # Описание проекта
```
